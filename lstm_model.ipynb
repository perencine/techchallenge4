{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-02T12:02:14.902927Z",
     "start_time": "2024-12-02T12:02:14.893241Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import optuna\n",
    "import pickle, joblib\n"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Verificação de valores e criação de features",
   "id": "4b56a847e7055ba0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T12:06:18.297057Z",
     "start_time": "2024-12-02T12:06:18.218305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_acao_bruto = pd.read_csv('base_historica\\\\AAPL_7anos.csv')\n",
    "df_acao_bruto['Date'] = pd.to_datetime(df_acao_bruto['Date'])\n",
    "df_acao_bruto.info()\n",
    "\n",
    "df_acao = df_acao_bruto[['Date', 'Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "df_acao['Weekday'] = df_acao_bruto['Date'].dt.weekday\n",
    "df_acao['Month'] = df_acao_bruto['Date'].dt.month\n",
    "df_acao['Year'] = df_acao_bruto['Date'].dt.year\n",
    "df_acao['day_sin'] = np.sin(2 * np.pi * df_acao_bruto['Date'].dt.dayofyear / 365)\n",
    "df_acao['day_cos'] = np.cos(2 * np.pi * df_acao_bruto['Date'].dt.dayofyear / 365)\n",
    "\n",
    "df_acao.head()\n"
   ],
   "id": "d9c4e16092e03f7b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1968 entries, 0 to 1967\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   Date       1968 non-null   datetime64[ns]\n",
      " 1   Open       1968 non-null   float64       \n",
      " 2   High       1968 non-null   float64       \n",
      " 3   Low        1968 non-null   float64       \n",
      " 4   Close      1968 non-null   float64       \n",
      " 5   Adj Close  1968 non-null   float64       \n",
      " 6   Volume     1968 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(5), int64(1)\n",
      "memory usage: 107.8 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "        Date       Open       High        Low      Close     Volume  Weekday  \\\n",
       "0 2017-01-03  28.950001  29.082500  28.690001  29.037500  115127600        1   \n",
       "1 2017-01-04  28.962500  29.127501  28.937500  29.004999   84472400        2   \n",
       "2 2017-01-05  28.980000  29.215000  28.952499  29.152500   88774400        3   \n",
       "3 2017-01-06  29.195000  29.540001  29.117500  29.477501  127007600        4   \n",
       "4 2017-01-09  29.487499  29.857500  29.485001  29.747499  134247600        0   \n",
       "\n",
       "   Month  Year   day_sin   day_cos  \n",
       "0      1  2017  0.051620  0.998667  \n",
       "1      1  2017  0.068802  0.997630  \n",
       "2      1  2017  0.085965  0.996298  \n",
       "3      1  2017  0.103102  0.994671  \n",
       "4      1  2017  0.154309  0.988023  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>28.950001</td>\n",
       "      <td>29.082500</td>\n",
       "      <td>28.690001</td>\n",
       "      <td>29.037500</td>\n",
       "      <td>115127600</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.051620</td>\n",
       "      <td>0.998667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>28.962500</td>\n",
       "      <td>29.127501</td>\n",
       "      <td>28.937500</td>\n",
       "      <td>29.004999</td>\n",
       "      <td>84472400</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.068802</td>\n",
       "      <td>0.997630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>28.980000</td>\n",
       "      <td>29.215000</td>\n",
       "      <td>28.952499</td>\n",
       "      <td>29.152500</td>\n",
       "      <td>88774400</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.085965</td>\n",
       "      <td>0.996298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>29.195000</td>\n",
       "      <td>29.540001</td>\n",
       "      <td>29.117500</td>\n",
       "      <td>29.477501</td>\n",
       "      <td>127007600</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.103102</td>\n",
       "      <td>0.994671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>29.487499</td>\n",
       "      <td>29.857500</td>\n",
       "      <td>29.485001</td>\n",
       "      <td>29.747499</td>\n",
       "      <td>134247600</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.154309</td>\n",
       "      <td>0.988023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Normalização dos dados ",
   "id": "3c0396153ca0d541"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T12:06:21.837476Z",
     "start_time": "2024-12-02T12:06:21.807369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cols_norm = ['Open', 'High', 'Low', 'Close', 'Volume', 'Weekday', 'Month', 'Year']\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler.fit(df_acao[cols_norm])\n",
    "df_acao[cols_norm] = scaler.transform(df_acao[cols_norm])\n",
    "\n",
    "df_acao.head()\n"
   ],
   "id": "a4c40829b82adacd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date      Open      High       Low     Close    Volume  Weekday  \\\n",
       "0 2017-01-03 -1.000000 -1.000000 -1.000000 -0.999687 -0.570271     -0.5   \n",
       "1 2017-01-04 -0.999880 -0.999568 -0.997594 -1.000000 -0.714908      0.0   \n",
       "2 2017-01-05 -0.999711 -0.998728 -0.997448 -0.998578 -0.694610      0.5   \n",
       "3 2017-01-06 -0.997639 -0.995610 -0.995845 -0.995445 -0.514219      1.0   \n",
       "4 2017-01-09 -0.994820 -0.992563 -0.992273 -0.992843 -0.480059     -1.0   \n",
       "\n",
       "   Month  Year   day_sin   day_cos  \n",
       "0   -1.0  -1.0  0.051620  0.998667  \n",
       "1   -1.0  -1.0  0.068802  0.997630  \n",
       "2   -1.0  -1.0  0.085965  0.996298  \n",
       "3   -1.0  -1.0  0.103102  0.994671  \n",
       "4   -1.0  -1.0  0.154309  0.988023  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999687</td>\n",
       "      <td>-0.570271</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.051620</td>\n",
       "      <td>0.998667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>-0.999880</td>\n",
       "      <td>-0.999568</td>\n",
       "      <td>-0.997594</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.714908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.068802</td>\n",
       "      <td>0.997630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>-0.999711</td>\n",
       "      <td>-0.998728</td>\n",
       "      <td>-0.997448</td>\n",
       "      <td>-0.998578</td>\n",
       "      <td>-0.694610</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.085965</td>\n",
       "      <td>0.996298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>-0.997639</td>\n",
       "      <td>-0.995610</td>\n",
       "      <td>-0.995845</td>\n",
       "      <td>-0.995445</td>\n",
       "      <td>-0.514219</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.103102</td>\n",
       "      <td>0.994671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>-0.994820</td>\n",
       "      <td>-0.992563</td>\n",
       "      <td>-0.992273</td>\n",
       "      <td>-0.992843</td>\n",
       "      <td>-0.480059</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.154309</td>\n",
       "      <td>0.988023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Salvar arquivo tratado",
   "id": "17ebfe6500886f05"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T05:21:58.469873Z",
     "start_time": "2024-12-02T05:21:58.400636Z"
    }
   },
   "cell_type": "code",
   "source": "df_acao.to_csv(f\"AAPL_7_years_data_norm.csv\", index=False)",
   "id": "bc96ad78c07ed56a",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Modelo ",
   "id": "f19f37a488fdeec2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T05:22:05.014171Z",
     "start_time": "2024-12-02T05:22:04.986079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size, output_size)\n",
    "        self.lstm2 = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm1(x, (h0, c0))\n",
    "        out = self.fc1(out[:, -1, :])\n",
    "        out, _ = self.lstm2(x, (h0, c0))\n",
    "        out = self.fc2(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model2(model, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for sequences, labels in test_loader:\n",
    "            sequences, labels = sequences.to(device), labels.to(device)\n",
    "            outputs = model(sequences)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    average_test_loss = test_loss / len(test_loader)\n",
    "    print(f\"Test Loss: {average_test_loss:.4f}\")\n",
    "    mlflow.log_metric(\"test_loss\", average_test_loss)\n",
    "    \n",
    "\n",
    "\n",
    "def train_model():\n",
    "    model = LSTM(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "    mlflow.set_experiment(\"Predicao_LSTM\")\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_params({\n",
    "        \"input_size\": input_size,\n",
    "        \"hidden_size\": hidden_size,\n",
    "        \"num_layers\": num_layers,\n",
    "        \"output_size\": output_size,\n",
    "        \"sequence_length\": sequence_length,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"num_epochs\": num_epochs\n",
    "        })\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            \n",
    "            for i, (sequences, labels) in enumerate(train_loader):\n",
    "                sequences, labels = sequences.to(device), labels.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(sequences)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Backward pass and optimization\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                # Log metrics every 100 batches\n",
    "                if i % 100 == 0:\n",
    "                    print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "                    mlflow.log_metric(\"train_loss\", running_loss / (i+1), step=epoch * len(train_loader) + i)\n",
    "\n",
    "        # Save the model\n",
    "        example_input = torch.randn(1, sequence_length, input_size).to(device)\n",
    "        example_input_np = example_input.cpu().numpy()\n",
    "        mlflow.pytorch.log_model(model, \"predicao_lstm\", input_example=example_input_np)\n",
    "        # evitar warning\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def tester(trial):\n",
    "    # range de parâmetros\n",
    "    hidden_size = trial.suggest_categorical(\"hidden_size\", [32, 64, 128, 256])\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 3)\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.0001, 0.01)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
    "    num_epochs = trial.suggest_int(\"num_epochs\", 30, 70)\n",
    "\n",
    "    train_dataset = TensorDataset(train_X, train_y)\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataset = TensorDataset(test_X, test_y)\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = LSTM(input_size=data.shape[1], hidden_size=hidden_size, num_layers=num_layers, output_size=1).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for sequences, labels in train_loader:\n",
    "            sequences, labels = sequences.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(sequences)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for sequences, labels in val_loader:\n",
    "            sequences, labels = sequences.to(device), labels.to(device)\n",
    "            outputs = model(sequences)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    return val_loss / len(val_loader)\n"
   ],
   "id": "2ab18a3046844e19",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Estudo dos melhores parâmetros",
   "id": "e063f27ca83ba477"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T07:12:13.528118Z",
     "start_time": "2024-12-02T05:22:35.743194Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data = df_acao[['Open', 'High', 'Low', 'Volume', 'Weekday', 'Month', 'Year', 'day_sin', 'day_cos']].values\n",
    "targets = df_acao[['Close']].values\n",
    "\n",
    "sequence_length = 20\n",
    "pre_X, pre_y = [], []\n",
    "for i in range(len(data) - sequence_length):\n",
    "    pre_X.append(data[i:i+sequence_length])\n",
    "    pre_y.append(targets[i+sequence_length])\n",
    "\n",
    "X = torch.tensor(np.array(pre_X), dtype=torch.float32)\n",
    "y = torch.tensor(np.array(pre_y), dtype=torch.float32)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "estudo = optuna.create_study()\n",
    "estudo.optimize(tester, n_trials=50)\n",
    "\n",
    "print(\"Melhores parâmetros:\", estudo.best_params)\n",
    "print(\"Melhor loss:\", estudo.best_value)\n"
   ],
   "id": "452690d39799f50d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-02 02:22:35,808] A new study created in memory with name: no-name-ae316e70-cdd9-4778-b0b5-9ead4d00c0dc\n",
      "C:\\Users\\vitor\\AppData\\Local\\Temp\\ipykernel_1576\\3639264506.py:94: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.0001, 0.01)\n",
      "[I 2024-12-02 02:24:04,552] Trial 0 finished with value: 0.02530330582521856 and parameters: {'hidden_size': 128, 'num_layers': 1, 'learning_rate': 0.00012546524058606881, 'batch_size': 128, 'num_epochs': 67}. Best is trial 0 with value: 0.02530330582521856.\n",
      "[I 2024-12-02 02:26:51,136] Trial 1 finished with value: 0.006129632138514093 and parameters: {'hidden_size': 256, 'num_layers': 1, 'learning_rate': 0.00018640690596259522, 'batch_size': 64, 'num_epochs': 46}. Best is trial 1 with value: 0.006129632138514093.\n",
      "[I 2024-12-02 02:27:05,126] Trial 2 finished with value: 0.02306084514462522 and parameters: {'hidden_size': 32, 'num_layers': 2, 'learning_rate': 0.00119126957642926, 'batch_size': 64, 'num_epochs': 30}. Best is trial 1 with value: 0.006129632138514093.\n",
      "[I 2024-12-02 02:28:37,823] Trial 3 finished with value: 0.003839485172647983 and parameters: {'hidden_size': 256, 'num_layers': 1, 'learning_rate': 0.0030929346484688406, 'batch_size': 128, 'num_epochs': 31}. Best is trial 3 with value: 0.003839485172647983.\n",
      "[I 2024-12-02 02:32:06,607] Trial 4 finished with value: 0.004363840230955527 and parameters: {'hidden_size': 128, 'num_layers': 2, 'learning_rate': 0.0006277161149605791, 'batch_size': 32, 'num_epochs': 70}. Best is trial 3 with value: 0.003839485172647983.\n",
      "[I 2024-12-02 02:32:50,260] Trial 5 finished with value: 0.013629706343635917 and parameters: {'hidden_size': 64, 'num_layers': 2, 'learning_rate': 0.004407569667317567, 'batch_size': 64, 'num_epochs': 43}. Best is trial 3 with value: 0.003839485172647983.\n",
      "[I 2024-12-02 02:33:42,155] Trial 6 finished with value: 0.00863754895648786 and parameters: {'hidden_size': 64, 'num_layers': 3, 'learning_rate': 0.002339759855642707, 'batch_size': 64, 'num_epochs': 33}. Best is trial 3 with value: 0.003839485172647983.\n",
      "[I 2024-12-02 02:35:30,457] Trial 7 finished with value: 0.005105984297447971 and parameters: {'hidden_size': 128, 'num_layers': 2, 'learning_rate': 0.0011691053733613008, 'batch_size': 64, 'num_epochs': 41}. Best is trial 3 with value: 0.003839485172647983.\n",
      "[I 2024-12-02 02:35:44,317] Trial 8 finished with value: 0.05000722587906888 and parameters: {'hidden_size': 32, 'num_layers': 1, 'learning_rate': 0.0001984135927145423, 'batch_size': 64, 'num_epochs': 52}. Best is trial 3 with value: 0.003839485172647983.\n",
      "[I 2024-12-02 02:38:06,425] Trial 9 finished with value: 0.0024212421433600995 and parameters: {'hidden_size': 128, 'num_layers': 2, 'learning_rate': 0.005330821896891344, 'batch_size': 64, 'num_epochs': 54}. Best is trial 9 with value: 0.0024212421433600995.\n",
      "[I 2024-12-02 02:42:39,187] Trial 10 finished with value: 0.010531292444703957 and parameters: {'hidden_size': 128, 'num_layers': 3, 'learning_rate': 0.005667514558839076, 'batch_size': 32, 'num_epochs': 58}. Best is trial 9 with value: 0.0024212421433600995.\n",
      "[I 2024-12-02 02:45:29,031] Trial 11 finished with value: 0.0021328454313334078 and parameters: {'hidden_size': 256, 'num_layers': 1, 'learning_rate': 0.009055214064198095, 'batch_size': 128, 'num_epochs': 56}. Best is trial 11 with value: 0.0021328454313334078.\n",
      "[I 2024-12-02 03:26:11,282] Trial 12 finished with value: 0.853574275970459 and parameters: {'hidden_size': 256, 'num_layers': 3, 'learning_rate': 0.009249713709798815, 'batch_size': 128, 'num_epochs': 58}. Best is trial 11 with value: 0.0021328454313334078.\n",
      "[I 2024-12-02 03:29:15,867] Trial 13 finished with value: 0.0037883229670114815 and parameters: {'hidden_size': 256, 'num_layers': 1, 'learning_rate': 0.009710465868593495, 'batch_size': 128, 'num_epochs': 57}. Best is trial 11 with value: 0.0021328454313334078.\n",
      "[I 2024-12-02 03:31:58,530] Trial 14 finished with value: 0.008079479914158583 and parameters: {'hidden_size': 128, 'num_layers': 2, 'learning_rate': 0.0021007589794306337, 'batch_size': 128, 'num_epochs': 63}. Best is trial 11 with value: 0.0021328454313334078.\n",
      "[I 2024-12-02 03:40:13,734] Trial 15 finished with value: 0.005206180391654085 and parameters: {'hidden_size': 256, 'num_layers': 2, 'learning_rate': 0.0005057660506305564, 'batch_size': 32, 'num_epochs': 52}. Best is trial 11 with value: 0.0021328454313334078.\n",
      "[I 2024-12-02 03:40:34,292] Trial 16 finished with value: 0.002457078720908612 and parameters: {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.005245874242370472, 'batch_size': 128, 'num_epochs': 49}. Best is trial 11 with value: 0.0021328454313334078.\n",
      "[I 2024-12-02 03:41:17,860] Trial 17 finished with value: 0.03579249984717795 and parameters: {'hidden_size': 32, 'num_layers': 3, 'learning_rate': 0.006718354686914145, 'batch_size': 64, 'num_epochs': 63}. Best is trial 11 with value: 0.0021328454313334078.\n",
      "[I 2024-12-02 03:44:00,941] Trial 18 finished with value: 0.0037015811540186405 and parameters: {'hidden_size': 256, 'num_layers': 1, 'learning_rate': 0.0034030641388788307, 'batch_size': 128, 'num_epochs': 54}. Best is trial 11 with value: 0.0021328454313334078.\n",
      "[I 2024-12-02 03:45:53,061] Trial 19 finished with value: 0.002816061126605536 and parameters: {'hidden_size': 128, 'num_layers': 2, 'learning_rate': 0.0017798262013204726, 'batch_size': 32, 'num_epochs': 38}. Best is trial 11 with value: 0.0021328454313334078.\n",
      "[I 2024-12-02 03:54:24,161] Trial 20 finished with value: 0.008957406040281057 and parameters: {'hidden_size': 256, 'num_layers': 2, 'learning_rate': 0.0006256835077529545, 'batch_size': 128, 'num_epochs': 62}. Best is trial 11 with value: 0.0021328454313334078.\n",
      "[I 2024-12-02 03:54:44,606] Trial 21 finished with value: 0.003754491714062169 and parameters: {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.006134615450471706, 'batch_size': 128, 'num_epochs': 48}. Best is trial 11 with value: 0.0021328454313334078.\n",
      "[I 2024-12-02 03:55:04,699] Trial 22 finished with value: 0.0019764988537644967 and parameters: {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.004573811282916056, 'batch_size': 128, 'num_epochs': 48}. Best is trial 22 with value: 0.0019764988537644967.\n",
      "[I 2024-12-02 03:55:27,655] Trial 23 finished with value: 0.003532925620675087 and parameters: {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.003378102588969336, 'batch_size': 128, 'num_epochs': 56}. Best is trial 22 with value: 0.0019764988537644967.\n",
      "[I 2024-12-02 03:55:46,965] Trial 24 finished with value: 0.001975661492906511 and parameters: {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.00864523171136962, 'batch_size': 128, 'num_epochs': 46}. Best is trial 24 with value: 0.001975661492906511.\n",
      "[I 2024-12-02 03:56:05,790] Trial 25 finished with value: 0.0020950546459062025 and parameters: {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.009913037634780218, 'batch_size': 128, 'num_epochs': 45}. Best is trial 24 with value: 0.001975661492906511.\n",
      "[I 2024-12-02 03:56:24,279] Trial 26 finished with value: 0.0032910528243519366 and parameters: {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.007219282000837889, 'batch_size': 128, 'num_epochs': 44}. Best is trial 24 with value: 0.001975661492906511.\n",
      "[I 2024-12-02 03:56:41,045] Trial 27 finished with value: 0.004746946069644764 and parameters: {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.004505608312350553, 'batch_size': 128, 'num_epochs': 40}. Best is trial 24 with value: 0.001975661492906511.\n",
      "[I 2024-12-02 03:56:55,690] Trial 28 finished with value: 0.002659446559846401 and parameters: {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.0074853076617280925, 'batch_size': 128, 'num_epochs': 35}. Best is trial 24 with value: 0.001975661492906511.\n",
      "[I 2024-12-02 03:57:15,264] Trial 29 finished with value: 0.0062975112232379615 and parameters: {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.002872514145324921, 'batch_size': 128, 'num_epochs': 47}. Best is trial 24 with value: 0.001975661492906511.\n",
      "[I 2024-12-02 03:57:31,185] Trial 30 finished with value: 0.003952056838897988 and parameters: {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.004021943469281392, 'batch_size': 128, 'num_epochs': 38}. Best is trial 24 with value: 0.001975661492906511.\n",
      "[I 2024-12-02 03:57:52,638] Trial 31 finished with value: 0.0026635595422703773 and parameters: {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.00971584161705873, 'batch_size': 128, 'num_epochs': 51}. Best is trial 24 with value: 0.001975661492906511.\n",
      "[I 2024-12-02 03:58:11,210] Trial 32 finished with value: 0.002311800082679838 and parameters: {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.009932256195531555, 'batch_size': 128, 'num_epochs': 45}. Best is trial 24 with value: 0.001975661492906511.\n",
      "[I 2024-12-02 03:58:21,822] Trial 33 finished with value: 0.014125961577519774 and parameters: {'hidden_size': 32, 'num_layers': 1, 'learning_rate': 0.007541544540923613, 'batch_size': 128, 'num_epochs': 49}. Best is trial 24 with value: 0.001975661492906511.\n",
      "[I 2024-12-02 03:58:39,319] Trial 34 finished with value: 0.1365058459341526 and parameters: {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.00010652316705035748, 'batch_size': 128, 'num_epochs': 42}. Best is trial 24 with value: 0.001975661492906511.\n",
      "[I 2024-12-02 04:01:13,942] Trial 35 finished with value: 0.07283817848656327 and parameters: {'hidden_size': 256, 'num_layers': 1, 'learning_rate': 0.007431404862287121, 'batch_size': 128, 'num_epochs': 46}. Best is trial 24 with value: 0.001975661492906511.\n",
      "[I 2024-12-02 04:01:46,996] Trial 36 finished with value: 0.0034895786442435705 and parameters: {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.0014889613236450836, 'batch_size': 32, 'num_epochs': 54}. Best is trial 24 with value: 0.001975661492906511.\n",
      "[I 2024-12-02 04:04:53,562] Trial 37 finished with value: 0.005070904939202592 and parameters: {'hidden_size': 256, 'num_layers': 1, 'learning_rate': 0.0003195793359638253, 'batch_size': 128, 'num_epochs': 61}. Best is trial 24 with value: 0.001975661492906511.\n",
      "[I 2024-12-02 04:05:13,072] Trial 38 finished with value: 0.004092920513357967 and parameters: {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.004388323980237294, 'batch_size': 128, 'num_epochs': 47}. Best is trial 24 with value: 0.001975661492906511.\n",
      "[I 2024-12-02 04:05:39,816] Trial 39 finished with value: 0.006129246990894899 and parameters: {'hidden_size': 32, 'num_layers': 2, 'learning_rate': 0.002996757674869923, 'batch_size': 128, 'num_epochs': 68}. Best is trial 24 with value: 0.001975661492906511.\n",
      "[I 2024-12-02 04:06:07,162] Trial 40 finished with value: 0.0023926108753165374 and parameters: {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.005362080698238673, 'batch_size': 32, 'num_epochs': 44}. Best is trial 24 with value: 0.001975661492906511.\n",
      "[I 2024-12-02 04:06:26,416] Trial 41 finished with value: 0.0029864884563721716 and parameters: {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.009644645736403485, 'batch_size': 128, 'num_epochs': 45}. Best is trial 24 with value: 0.001975661492906511.\n",
      "[I 2024-12-02 04:06:43,498] Trial 42 finished with value: 0.0027350979507900774 and parameters: {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.008429397448226428, 'batch_size': 128, 'num_epochs': 40}. Best is trial 24 with value: 0.001975661492906511.\n",
      "[I 2024-12-02 04:07:04,773] Trial 43 finished with value: 0.004936792218359187 and parameters: {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.00617546246369537, 'batch_size': 128, 'num_epochs': 51}. Best is trial 24 with value: 0.001975661492906511.\n",
      "[I 2024-12-02 04:07:22,551] Trial 44 finished with value: 0.002938343124696985 and parameters: {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.008276417668270225, 'batch_size': 128, 'num_epochs': 43}. Best is trial 24 with value: 0.001975661492906511.\n",
      "[I 2024-12-02 04:09:52,773] Trial 45 finished with value: 0.016080356036712016 and parameters: {'hidden_size': 256, 'num_layers': 1, 'learning_rate': 0.0009789299703821266, 'batch_size': 64, 'num_epochs': 46}. Best is trial 24 with value: 0.001975661492906511.\n",
      "[I 2024-12-02 04:10:37,721] Trial 46 finished with value: 0.009824425680562854 and parameters: {'hidden_size': 64, 'num_layers': 2, 'learning_rate': 0.004927802577116159, 'batch_size': 128, 'num_epochs': 50}. Best is trial 24 with value: 0.001975661492906511.\n",
      "[I 2024-12-02 04:11:02,521] Trial 47 finished with value: 0.004777807625941932 and parameters: {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.003908732376231113, 'batch_size': 128, 'num_epochs': 60}. Best is trial 24 with value: 0.001975661492906511.\n",
      "[I 2024-12-02 04:11:16,661] Trial 48 finished with value: 0.003958569107843297 and parameters: {'hidden_size': 32, 'num_layers': 1, 'learning_rate': 0.009832413762813663, 'batch_size': 64, 'num_epochs': 53}. Best is trial 24 with value: 0.001975661492906511.\n",
      "[I 2024-12-02 04:12:13,522] Trial 49 finished with value: 0.0038276634295471013 and parameters: {'hidden_size': 128, 'num_layers': 1, 'learning_rate': 0.0024235680459047866, 'batch_size': 128, 'num_epochs': 56}. Best is trial 24 with value: 0.001975661492906511.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros: {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.00864523171136962, 'batch_size': 128, 'num_epochs': 46}\n",
      "Melhor loss: 0.001975661492906511\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Treinamento do modelo com os melhores parâmetros",
   "id": "4ce8a4ad090217a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T07:12:40.445113Z",
     "start_time": "2024-12-02T07:12:13.532144Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#best_params = {'hidden_size': 128, 'num_layers': 2, 'learning_rate': 0.005121810661211535, 'batch_size': 64, 'num_epochs': 30}\n",
    "#best_params = {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.00864523171136962, 'batch_size': 128, 'num_epochs': 46}\n",
    "\n",
    "input_size = data.shape[1]\n",
    "hidden_size = estudo.best_params['hidden_size']\n",
    "num_layers = estudo.best_params['num_layers']\n",
    "num_epochs = estudo.best_params['num_epochs']\n",
    "batch_size = estudo.best_params['batch_size']\n",
    "learning_rate = estudo.best_params['learning_rate']\n",
    "sequence_length = 20\n",
    "output_size = 1\n",
    "\n",
    "train_dataset = TensorDataset(train_X, train_y)\n",
    "test_dataset = TensorDataset(test_X, test_y)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = train_model()"
   ],
   "id": "b752e17655722dcc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/46], Step [1/13], Loss: 0.5155\n",
      "Epoch [2/46], Step [1/13], Loss: 0.0112\n",
      "Epoch [3/46], Step [1/13], Loss: 0.0035\n",
      "Epoch [4/46], Step [1/13], Loss: 0.0026\n",
      "Epoch [5/46], Step [1/13], Loss: 0.0014\n",
      "Epoch [6/46], Step [1/13], Loss: 0.0013\n",
      "Epoch [7/46], Step [1/13], Loss: 0.0013\n",
      "Epoch [8/46], Step [1/13], Loss: 0.0012\n",
      "Epoch [9/46], Step [1/13], Loss: 0.0008\n",
      "Epoch [10/46], Step [1/13], Loss: 0.0007\n",
      "Epoch [11/46], Step [1/13], Loss: 0.0008\n",
      "Epoch [12/46], Step [1/13], Loss: 0.0006\n",
      "Epoch [13/46], Step [1/13], Loss: 0.0008\n",
      "Epoch [14/46], Step [1/13], Loss: 0.0008\n",
      "Epoch [15/46], Step [1/13], Loss: 0.0010\n",
      "Epoch [16/46], Step [1/13], Loss: 0.0008\n",
      "Epoch [17/46], Step [1/13], Loss: 0.0007\n",
      "Epoch [18/46], Step [1/13], Loss: 0.0006\n",
      "Epoch [19/46], Step [1/13], Loss: 0.0005\n",
      "Epoch [20/46], Step [1/13], Loss: 0.0006\n",
      "Epoch [21/46], Step [1/13], Loss: 0.0007\n",
      "Epoch [22/46], Step [1/13], Loss: 0.0005\n",
      "Epoch [23/46], Step [1/13], Loss: 0.0007\n",
      "Epoch [24/46], Step [1/13], Loss: 0.0006\n",
      "Epoch [25/46], Step [1/13], Loss: 0.0005\n",
      "Epoch [26/46], Step [1/13], Loss: 0.0006\n",
      "Epoch [27/46], Step [1/13], Loss: 0.0006\n",
      "Epoch [28/46], Step [1/13], Loss: 0.0008\n",
      "Epoch [29/46], Step [1/13], Loss: 0.0008\n",
      "Epoch [30/46], Step [1/13], Loss: 0.0006\n",
      "Epoch [31/46], Step [1/13], Loss: 0.0005\n",
      "Epoch [32/46], Step [1/13], Loss: 0.0008\n",
      "Epoch [33/46], Step [1/13], Loss: 0.0006\n",
      "Epoch [34/46], Step [1/13], Loss: 0.0008\n",
      "Epoch [35/46], Step [1/13], Loss: 0.0004\n",
      "Epoch [36/46], Step [1/13], Loss: 0.0006\n",
      "Epoch [37/46], Step [1/13], Loss: 0.0007\n",
      "Epoch [38/46], Step [1/13], Loss: 0.0006\n",
      "Epoch [39/46], Step [1/13], Loss: 0.0008\n",
      "Epoch [40/46], Step [1/13], Loss: 0.0005\n",
      "Epoch [41/46], Step [1/13], Loss: 0.0006\n",
      "Epoch [42/46], Step [1/13], Loss: 0.0005\n",
      "Epoch [43/46], Step [1/13], Loss: 0.0005\n",
      "Epoch [44/46], Step [1/13], Loss: 0.0006\n",
      "Epoch [45/46], Step [1/13], Loss: 0.0006\n",
      "Epoch [46/46], Step [1/13], Loss: 0.0007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/8 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "56baf6cf8f844802a1c55891580ab58f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T07:12:40.557825Z",
     "start_time": "2024-12-02T07:12:40.445113Z"
    }
   },
   "cell_type": "code",
   "source": "evaluate_model2(model, nn.MSELoss())",
   "id": "386baceb4e4230e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0034\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T12:08:34.007688Z",
     "start_time": "2024-12-02T12:08:33.993254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mlflow.end_run()\n",
    "torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'hyperparameters': {\n",
    "            'input_size': input_size,\n",
    "            'hidden_size': hidden_size,\n",
    "            'num_layers': num_layers,\n",
    "            'num_epochs': num_epochs,\n",
    "            'batch_size': batch_size,\n",
    "            'output_size': output_size,\n",
    "            'learning_rate': learning_rate\n",
    "        }\n",
    "    }, 'modelo_aapl_lstm.pth')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "    "
   ],
   "id": "a1f071428a0849d3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
