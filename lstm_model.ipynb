{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-30T16:56:33.108956Z",
     "start_time": "2024-11-30T16:56:27.336035Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import optuna\n",
    "import joblib\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Verificação de valores e criação de features",
   "id": "4b56a847e7055ba0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T16:56:33.186367Z",
     "start_time": "2024-11-30T16:56:33.111970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_acao_bruto = pd.read_csv('base_historica\\\\AAPL_7anos.csv')\n",
    "df_acao_bruto['Date'] = pd.to_datetime(df_acao_bruto['Date'])\n",
    "df_acao_bruto.info()\n",
    "\n",
    "df_acao = df_acao_bruto[['Date', 'Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "df_acao['Weekday'] = df_acao_bruto['Date'].dt.weekday\n",
    "df_acao['Month'] = df_acao_bruto['Date'].dt.month\n",
    "df_acao['Year'] = df_acao_bruto['Date'].dt.year\n",
    "df_acao['day_sin'] = np.sin(2 * np.pi * df_acao_bruto['Date'].dt.dayofyear / 365)\n",
    "df_acao['day_cos'] = np.cos(2 * np.pi * df_acao_bruto['Date'].dt.dayofyear / 365)\n",
    "\n",
    "df_acao.head()\n"
   ],
   "id": "d9c4e16092e03f7b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1760 entries, 0 to 1759\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   Date       1760 non-null   datetime64[ns]\n",
      " 1   Open       1760 non-null   float64       \n",
      " 2   High       1760 non-null   float64       \n",
      " 3   Low        1760 non-null   float64       \n",
      " 4   Close      1760 non-null   float64       \n",
      " 5   Adj Close  1760 non-null   float64       \n",
      " 6   Volume     1760 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(5), int64(1)\n",
      "memory usage: 96.4 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "        Date       Open       High        Low      Close     Volume  Weekday  \\\n",
       "0 2017-01-03  28.950001  29.082500  28.690001  29.037500  115127600        1   \n",
       "1 2017-01-04  28.962500  29.127501  28.937500  29.004999   84472400        2   \n",
       "2 2017-01-05  28.980000  29.215000  28.952499  29.152500   88774400        3   \n",
       "3 2017-01-06  29.195000  29.540001  29.117500  29.477501  127007600        4   \n",
       "4 2017-01-09  29.487499  29.857500  29.485001  29.747499  134247600        0   \n",
       "\n",
       "   Month  Year   day_sin   day_cos  \n",
       "0      1  2017  0.051620  0.998667  \n",
       "1      1  2017  0.068802  0.997630  \n",
       "2      1  2017  0.085965  0.996298  \n",
       "3      1  2017  0.103102  0.994671  \n",
       "4      1  2017  0.154309  0.988023  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>28.950001</td>\n",
       "      <td>29.082500</td>\n",
       "      <td>28.690001</td>\n",
       "      <td>29.037500</td>\n",
       "      <td>115127600</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.051620</td>\n",
       "      <td>0.998667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>28.962500</td>\n",
       "      <td>29.127501</td>\n",
       "      <td>28.937500</td>\n",
       "      <td>29.004999</td>\n",
       "      <td>84472400</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.068802</td>\n",
       "      <td>0.997630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>28.980000</td>\n",
       "      <td>29.215000</td>\n",
       "      <td>28.952499</td>\n",
       "      <td>29.152500</td>\n",
       "      <td>88774400</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.085965</td>\n",
       "      <td>0.996298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>29.195000</td>\n",
       "      <td>29.540001</td>\n",
       "      <td>29.117500</td>\n",
       "      <td>29.477501</td>\n",
       "      <td>127007600</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.103102</td>\n",
       "      <td>0.994671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>29.487499</td>\n",
       "      <td>29.857500</td>\n",
       "      <td>29.485001</td>\n",
       "      <td>29.747499</td>\n",
       "      <td>134247600</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.154309</td>\n",
       "      <td>0.988023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Normalização dos dados ",
   "id": "3c0396153ca0d541"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T16:56:33.255866Z",
     "start_time": "2024-11-30T16:56:33.190391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cols_norm = ['Open', 'High', 'Low', 'Close', 'Volume', 'Weekday', 'Month', 'Year']\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "df_acao[cols_norm] = scaler.fit_transform(df_acao[cols_norm])\n",
    "\n",
    "df_acao.head()\n"
   ],
   "id": "a4c40829b82adacd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date      Open      High       Low     Close    Volume  Weekday  \\\n",
       "0 2017-01-03 -1.000000 -1.000000 -1.000000 -0.999616 -0.570271     -0.5   \n",
       "1 2017-01-04 -0.999852 -0.999472 -0.997059 -1.000000 -0.714908      0.0   \n",
       "2 2017-01-05 -0.999645 -0.998446 -0.996881 -0.998256 -0.694610      0.5   \n",
       "3 2017-01-06 -0.997102 -0.994635 -0.994920 -0.994412 -0.514219      1.0   \n",
       "4 2017-01-09 -0.993642 -0.990911 -0.990553 -0.991218 -0.480059     -1.0   \n",
       "\n",
       "   Month  Year   day_sin   day_cos  \n",
       "0   -1.0  -1.0  0.051620  0.998667  \n",
       "1   -1.0  -1.0  0.068802  0.997630  \n",
       "2   -1.0  -1.0  0.085965  0.996298  \n",
       "3   -1.0  -1.0  0.103102  0.994671  \n",
       "4   -1.0  -1.0  0.154309  0.988023  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999616</td>\n",
       "      <td>-0.570271</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.051620</td>\n",
       "      <td>0.998667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>-0.999852</td>\n",
       "      <td>-0.999472</td>\n",
       "      <td>-0.997059</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.714908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.068802</td>\n",
       "      <td>0.997630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>-0.999645</td>\n",
       "      <td>-0.998446</td>\n",
       "      <td>-0.996881</td>\n",
       "      <td>-0.998256</td>\n",
       "      <td>-0.694610</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.085965</td>\n",
       "      <td>0.996298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>-0.997102</td>\n",
       "      <td>-0.994635</td>\n",
       "      <td>-0.994920</td>\n",
       "      <td>-0.994412</td>\n",
       "      <td>-0.514219</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.103102</td>\n",
       "      <td>0.994671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>-0.993642</td>\n",
       "      <td>-0.990911</td>\n",
       "      <td>-0.990553</td>\n",
       "      <td>-0.991218</td>\n",
       "      <td>-0.480059</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.154309</td>\n",
       "      <td>0.988023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Salvar arquivo tratado",
   "id": "17ebfe6500886f05"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T16:56:33.347159Z",
     "start_time": "2024-11-30T16:56:33.260620Z"
    }
   },
   "cell_type": "code",
   "source": "df_acao.to_csv(f\"AAPL_7_years_data_norm.csv\", index=False)",
   "id": "bc96ad78c07ed56a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Modelo ",
   "id": "f19f37a488fdeec2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T16:56:33.641090Z",
     "start_time": "2024-11-30T16:56:33.351171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size, output_size)\n",
    "        self.lstm2 = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm1(x, (h0, c0))\n",
    "        out = self.fc1(out[:, -1, :])\n",
    "        out, _ = self.lstm2(x, (h0, c0))\n",
    "        out = self.fc2(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model2(model, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for sequences, labels in test_loader:\n",
    "            sequences, labels = sequences.to(device), labels.to(device)\n",
    "            outputs = model(sequences)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    average_test_loss = test_loss / len(test_loader)\n",
    "    print(f\"Test Loss: {average_test_loss:.4f}\")\n",
    "    mlflow.log_metric(\"test_loss\", average_test_loss)\n",
    "    \n",
    "\n",
    "\n",
    "def train_model():\n",
    "    model = LSTM(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "    mlflow.set_experiment(\"Predicao_LSTM\")\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_params({\n",
    "        \"input_size\": input_size,\n",
    "        \"hidden_size\": hidden_size,\n",
    "        \"num_layers\": num_layers,\n",
    "        \"output_size\": output_size,\n",
    "        \"sequence_length\": sequence_length,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"num_epochs\": num_epochs\n",
    "        })\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            \n",
    "            for i, (sequences, labels) in enumerate(train_loader):\n",
    "                sequences, labels = sequences.to(device), labels.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(sequences)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Backward pass and optimization\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                # Log metrics every 100 batches\n",
    "                if i % 100 == 0:\n",
    "                    print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "                    mlflow.log_metric(\"train_loss\", running_loss / (i+1), step=epoch * len(train_loader) + i)\n",
    "\n",
    "        # Save the model\n",
    "        example_input = torch.randn(1, sequence_length, input_size).to(device)\n",
    "        example_input_np = example_input.cpu().numpy()\n",
    "        mlflow.pytorch.log_model(model, \"predicao_lstm\", input_example=example_input_np)\n",
    "        # evitar warning\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def tester(trial):\n",
    "    # range de parâmetros\n",
    "    hidden_size = trial.suggest_categorical(\"hidden_size\", [32, 64, 128, 256])\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 3)\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.0001, 0.01)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
    "    num_epochs = trial.suggest_int(\"num_epochs\", 30, 70)\n",
    "\n",
    "    train_dataset = TensorDataset(train_X, train_y)\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataset = TensorDataset(test_X, test_y)\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = LSTM(input_size=data.shape[1], hidden_size=hidden_size, num_layers=num_layers, output_size=1).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for sequences, labels in train_loader:\n",
    "            sequences, labels = sequences.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(sequences)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for sequences, labels in val_loader:\n",
    "            sequences, labels = sequences.to(device), labels.to(device)\n",
    "            outputs = model(sequences)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    return val_loss / len(val_loader)\n"
   ],
   "id": "2ab18a3046844e19",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Estudo dos melhores parâmetros",
   "id": "e063f27ca83ba477"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T18:33:34.684581Z",
     "start_time": "2024-11-30T16:56:33.648408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data = df_acao[['Open', 'High', 'Low', 'Volume', 'Weekday', 'Month', 'Year', 'day_sin', 'day_cos']].values\n",
    "targets = df_acao[['Close']].values\n",
    "\n",
    "sequence_length = 20\n",
    "pre_X, pre_y = [], []\n",
    "for i in range(len(data) - sequence_length):\n",
    "    pre_X.append(data[i:i+sequence_length])\n",
    "    pre_y.append(targets[i+sequence_length])\n",
    "\n",
    "X = torch.tensor(np.array(pre_X), dtype=torch.float32)\n",
    "y = torch.tensor(np.array(pre_y), dtype=torch.float32)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "estudo = optuna.create_study()\n",
    "estudo.optimize(tester, n_trials=50)\n",
    "\n",
    "print(\"Melhores parâmetros:\", estudo.best_params)\n",
    "print(\"Melhor loss:\", estudo.best_value)\n"
   ],
   "id": "452690d39799f50d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 13:56:33,683] A new study created in memory with name: no-name-bfbf5b92-fab2-4386-97cb-56a44b8c9eac\n",
      "C:\\Users\\vitor\\AppData\\Local\\Temp\\ipykernel_16008\\3639264506.py:94: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.0001, 0.01)\n",
      "[I 2024-11-30 13:56:41,498] Trial 0 finished with value: 0.02276245690882206 and parameters: {'hidden_size': 32, 'num_layers': 1, 'learning_rate': 0.0002986819767573223, 'batch_size': 128, 'num_epochs': 34}. Best is trial 0 with value: 0.02276245690882206.\n",
      "C:\\Users\\vitor\\AppData\\Local\\Temp\\ipykernel_16008\\3639264506.py:94: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.0001, 0.01)\n",
      "[I 2024-11-30 14:02:07,900] Trial 1 finished with value: 0.005280295545658605 and parameters: {'hidden_size': 256, 'num_layers': 3, 'learning_rate': 0.0006763853400375858, 'batch_size': 32, 'num_epochs': 57}. Best is trial 1 with value: 0.005280295545658605.\n",
      "[I 2024-11-30 14:02:22,102] Trial 2 finished with value: 0.011547068677221736 and parameters: {'hidden_size': 32, 'num_layers': 2, 'learning_rate': 0.0014489423269265262, 'batch_size': 64, 'num_epochs': 55}. Best is trial 1 with value: 0.005280295545658605.\n",
      "[I 2024-11-30 14:02:52,087] Trial 3 finished with value: 0.0053764875046908855 and parameters: {'hidden_size': 64, 'num_layers': 2, 'learning_rate': 0.00042107846608632125, 'batch_size': 64, 'num_epochs': 59}. Best is trial 1 with value: 0.005280295545658605.\n",
      "[I 2024-11-30 14:08:13,718] Trial 4 finished with value: 0.006761328278419872 and parameters: {'hidden_size': 256, 'num_layers': 2, 'learning_rate': 0.00017181506692246385, 'batch_size': 64, 'num_epochs': 55}. Best is trial 1 with value: 0.005280295545658605.\n",
      "[I 2024-11-30 14:08:44,074] Trial 5 finished with value: 0.004164461376300703 and parameters: {'hidden_size': 32, 'num_layers': 3, 'learning_rate': 0.005315288313948955, 'batch_size': 64, 'num_epochs': 39}. Best is trial 5 with value: 0.004164461376300703.\n",
      "[I 2024-11-30 14:09:15,986] Trial 6 finished with value: 0.014100950987388691 and parameters: {'hidden_size': 32, 'num_layers': 3, 'learning_rate': 0.0006779335390605121, 'batch_size': 64, 'num_epochs': 38}. Best is trial 5 with value: 0.004164461376300703.\n",
      "[I 2024-11-30 14:11:33,600] Trial 7 finished with value: 0.006104912608861923 and parameters: {'hidden_size': 256, 'num_layers': 1, 'learning_rate': 0.0007078487962497578, 'batch_size': 64, 'num_epochs': 49}. Best is trial 5 with value: 0.004164461376300703.\n",
      "[I 2024-11-30 14:13:37,545] Trial 8 finished with value: 0.007903579312066237 and parameters: {'hidden_size': 128, 'num_layers': 2, 'learning_rate': 0.00018367251761096956, 'batch_size': 128, 'num_epochs': 48}. Best is trial 5 with value: 0.004164461376300703.\n",
      "[I 2024-11-30 14:14:01,822] Trial 9 finished with value: 0.0038797779283909636 and parameters: {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.0008949436483974088, 'batch_size': 32, 'num_epochs': 38}. Best is trial 9 with value: 0.0038797779283909636.\n",
      "[I 2024-11-30 14:15:01,781] Trial 10 finished with value: 0.0037787938596342096 and parameters: {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.0026652546938114564, 'batch_size': 32, 'num_epochs': 70}. Best is trial 10 with value: 0.0037787938596342096.\n",
      "[I 2024-11-30 14:15:52,369] Trial 11 finished with value: 0.005220764380117709 and parameters: {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.002487239993737935, 'batch_size': 32, 'num_epochs': 68}. Best is trial 10 with value: 0.0037787938596342096.\n",
      "[I 2024-11-30 14:16:31,530] Trial 12 finished with value: 0.0036746141585436735 and parameters: {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.00752962319390286, 'batch_size': 32, 'num_epochs': 70}. Best is trial 12 with value: 0.0036746141585436735.\n",
      "[I 2024-11-30 14:17:12,873] Trial 13 finished with value: 0.0030036096207120204 and parameters: {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.008066910801153753, 'batch_size': 32, 'num_epochs': 70}. Best is trial 13 with value: 0.0030036096207120204.\n",
      "[I 2024-11-30 14:17:55,534] Trial 14 finished with value: 0.002327224197374149 and parameters: {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.009469566175119768, 'batch_size': 32, 'num_epochs': 64}. Best is trial 14 with value: 0.002327224197374149.\n",
      "[I 2024-11-30 14:21:04,555] Trial 15 finished with value: 0.0023902114692398095 and parameters: {'hidden_size': 128, 'num_layers': 2, 'learning_rate': 0.008147140830702539, 'batch_size': 32, 'num_epochs': 63}. Best is trial 14 with value: 0.002327224197374149.\n",
      "[I 2024-11-30 14:24:10,275] Trial 16 finished with value: 0.004937304215590385 and parameters: {'hidden_size': 128, 'num_layers': 2, 'learning_rate': 0.004095566416003596, 'batch_size': 32, 'num_epochs': 63}. Best is trial 14 with value: 0.002327224197374149.\n",
      "[I 2024-11-30 14:28:23,409] Trial 17 finished with value: 0.007541950305246494 and parameters: {'hidden_size': 128, 'num_layers': 3, 'learning_rate': 0.0098824083558691, 'batch_size': 32, 'num_epochs': 63}. Best is trial 14 with value: 0.002327224197374149.\n",
      "[I 2024-11-30 14:30:33,846] Trial 18 finished with value: 0.0030950764970233044 and parameters: {'hidden_size': 128, 'num_layers': 2, 'learning_rate': 0.0019445988601992214, 'batch_size': 128, 'num_epochs': 63}. Best is trial 14 with value: 0.002327224197374149.\n",
      "[I 2024-11-30 14:32:45,947] Trial 19 finished with value: 0.0027485047255388713 and parameters: {'hidden_size': 128, 'num_layers': 2, 'learning_rate': 0.004459344133621196, 'batch_size': 32, 'num_epochs': 52}. Best is trial 14 with value: 0.002327224197374149.\n",
      "[I 2024-11-30 14:34:35,782] Trial 20 finished with value: 0.0021563288120722227 and parameters: {'hidden_size': 128, 'num_layers': 2, 'learning_rate': 0.005130547232547332, 'batch_size': 32, 'num_epochs': 43}. Best is trial 20 with value: 0.0021563288120722227.\n",
      "[I 2024-11-30 14:36:23,333] Trial 21 finished with value: 0.005536141080400822 and parameters: {'hidden_size': 128, 'num_layers': 2, 'learning_rate': 0.005497114990022029, 'batch_size': 32, 'num_epochs': 42}. Best is trial 20 with value: 0.0021563288120722227.\n",
      "[I 2024-11-30 14:38:16,062] Trial 22 finished with value: 0.0038380134554410524 and parameters: {'hidden_size': 128, 'num_layers': 2, 'learning_rate': 0.0030809339978584292, 'batch_size': 32, 'num_epochs': 44}. Best is trial 20 with value: 0.0021563288120722227.\n",
      "[I 2024-11-30 14:40:26,393] Trial 23 finished with value: 0.003136170374504714 and parameters: {'hidden_size': 128, 'num_layers': 3, 'learning_rate': 0.006851334009040699, 'batch_size': 32, 'num_epochs': 32}. Best is trial 20 with value: 0.0021563288120722227.\n",
      "[I 2024-11-30 14:41:39,682] Trial 24 finished with value: 0.0042336381950669666 and parameters: {'hidden_size': 128, 'num_layers': 1, 'learning_rate': 0.009381262662051424, 'batch_size': 32, 'num_epochs': 65}. Best is trial 20 with value: 0.0021563288120722227.\n",
      "[I 2024-11-30 14:43:43,367] Trial 25 finished with value: 0.00996402914946278 and parameters: {'hidden_size': 128, 'num_layers': 2, 'learning_rate': 0.0016225374847942157, 'batch_size': 128, 'num_epochs': 60}. Best is trial 20 with value: 0.0021563288120722227.\n",
      "[I 2024-11-30 14:44:51,279] Trial 26 finished with value: 0.004609342399899932 and parameters: {'hidden_size': 64, 'num_layers': 3, 'learning_rate': 0.0037096068057002403, 'batch_size': 32, 'num_epochs': 43}. Best is trial 20 with value: 0.0021563288120722227.\n",
      "[I 2024-11-30 14:50:54,019] Trial 27 finished with value: 0.00600116559706459 and parameters: {'hidden_size': 256, 'num_layers': 2, 'learning_rate': 0.005520561782011906, 'batch_size': 32, 'num_epochs': 46}. Best is trial 20 with value: 0.0021563288120722227.\n",
      "[I 2024-11-30 14:52:01,605] Trial 28 finished with value: 0.0036906226093626833 and parameters: {'hidden_size': 128, 'num_layers': 1, 'learning_rate': 0.006146521070392697, 'batch_size': 32, 'num_epochs': 60}. Best is trial 20 with value: 0.0021563288120722227.\n",
      "[I 2024-11-30 14:52:18,530] Trial 29 finished with value: 0.005657591624185443 and parameters: {'hidden_size': 32, 'num_layers': 2, 'learning_rate': 0.003697433096564972, 'batch_size': 128, 'num_epochs': 52}. Best is trial 20 with value: 0.0021563288120722227.\n",
      "[I 2024-11-30 14:52:37,155] Trial 30 finished with value: 0.0037799935089424253 and parameters: {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.009491058837763394, 'batch_size': 32, 'num_epochs': 35}. Best is trial 20 with value: 0.0021563288120722227.\n",
      "[I 2024-11-30 14:54:51,591] Trial 31 finished with value: 0.002369265992787074 and parameters: {'hidden_size': 128, 'num_layers': 2, 'learning_rate': 0.004165204706583464, 'batch_size': 32, 'num_epochs': 52}. Best is trial 20 with value: 0.0021563288120722227.\n",
      "[I 2024-11-30 14:57:38,245] Trial 32 finished with value: 0.00581193079282953 and parameters: {'hidden_size': 128, 'num_layers': 2, 'learning_rate': 0.006792461795821658, 'batch_size': 32, 'num_epochs': 65}. Best is trial 20 with value: 0.0021563288120722227.\n",
      "[I 2024-11-30 15:00:04,455] Trial 33 finished with value: 0.006657654800536958 and parameters: {'hidden_size': 128, 'num_layers': 2, 'learning_rate': 0.0001018849191766432, 'batch_size': 32, 'num_epochs': 57}. Best is trial 20 with value: 0.0021563288120722227.\n",
      "[I 2024-11-30 15:02:27,198] Trial 34 finished with value: 0.0034917857265099883 and parameters: {'hidden_size': 128, 'num_layers': 2, 'learning_rate': 0.0012591472260001914, 'batch_size': 32, 'num_epochs': 54}. Best is trial 20 with value: 0.0021563288120722227.\n",
      "[I 2024-11-30 15:14:13,912] Trial 35 finished with value: 0.0024523780977522783 and parameters: {'hidden_size': 256, 'num_layers': 3, 'learning_rate': 0.002342737678235163, 'batch_size': 32, 'num_epochs': 57}. Best is trial 20 with value: 0.0021563288120722227.\n",
      "[I 2024-11-30 15:14:28,834] Trial 36 finished with value: 0.003816703916527331 and parameters: {'hidden_size': 32, 'num_layers': 2, 'learning_rate': 0.004748193015380249, 'batch_size': 128, 'num_epochs': 47}. Best is trial 20 with value: 0.0021563288120722227.\n",
      "[I 2024-11-30 15:16:53,161] Trial 37 finished with value: 0.006404645275324583 and parameters: {'hidden_size': 128, 'num_layers': 2, 'learning_rate': 0.00035318040139661086, 'batch_size': 64, 'num_epochs': 67}. Best is trial 20 with value: 0.0021563288120722227.\n",
      "[I 2024-11-30 15:27:31,313] Trial 38 finished with value: 0.005132930644322187 and parameters: {'hidden_size': 256, 'num_layers': 3, 'learning_rate': 0.003239214827295183, 'batch_size': 32, 'num_epochs': 51}. Best is trial 20 with value: 0.0021563288120722227.\n",
      "[I 2024-11-30 15:28:18,374] Trial 39 finished with value: 0.0031781003538829586 and parameters: {'hidden_size': 64, 'num_layers': 2, 'learning_rate': 0.0075135145737387585, 'batch_size': 64, 'num_epochs': 54}. Best is trial 20 with value: 0.0021563288120722227.\n",
      "[I 2024-11-30 15:28:31,726] Trial 40 finished with value: 0.002450172590959648 and parameters: {'hidden_size': 32, 'num_layers': 1, 'learning_rate': 0.004865750000158056, 'batch_size': 32, 'num_epochs': 41}. Best is trial 20 with value: 0.0021563288120722227.\n",
      "[I 2024-11-30 15:28:43,463] Trial 41 finished with value: 0.0030866623750295153 and parameters: {'hidden_size': 32, 'num_layers': 1, 'learning_rate': 0.00537118121401927, 'batch_size': 32, 'num_epochs': 36}. Best is trial 20 with value: 0.0021563288120722227.\n",
      "[I 2024-11-30 15:28:56,954] Trial 42 finished with value: 0.0031834121857007795 and parameters: {'hidden_size': 32, 'num_layers': 1, 'learning_rate': 0.004501567460725216, 'batch_size': 32, 'num_epochs': 40}. Best is trial 20 with value: 0.0021563288120722227.\n",
      "[I 2024-11-30 15:29:12,593] Trial 43 finished with value: 0.0043465654281052675 and parameters: {'hidden_size': 32, 'num_layers': 1, 'learning_rate': 0.008218086538864067, 'batch_size': 32, 'num_epochs': 45}. Best is trial 20 with value: 0.0021563288120722227.\n",
      "[I 2024-11-30 15:29:26,074] Trial 44 finished with value: 0.003059931988404556 and parameters: {'hidden_size': 32, 'num_layers': 1, 'learning_rate': 0.0030408264739045215, 'batch_size': 32, 'num_epochs': 41}. Best is trial 20 with value: 0.0021563288120722227.\n",
      "[I 2024-11-30 15:29:33,132] Trial 45 finished with value: 0.0031701959669589996 and parameters: {'hidden_size': 32, 'num_layers': 1, 'learning_rate': 0.0062311882739769725, 'batch_size': 64, 'num_epochs': 31}. Best is trial 20 with value: 0.0021563288120722227.\n",
      "[I 2024-11-30 15:29:58,887] Trial 46 finished with value: 0.004409897913732989 and parameters: {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.002187323355300701, 'batch_size': 32, 'num_epochs': 49}. Best is trial 20 with value: 0.0021563288120722227.\n",
      "[I 2024-11-30 15:31:38,363] Trial 47 finished with value: 0.005458689580502158 and parameters: {'hidden_size': 128, 'num_layers': 2, 'learning_rate': 0.0005674386403927762, 'batch_size': 32, 'num_epochs': 38}. Best is trial 20 with value: 0.0021563288120722227.\n",
      "[I 2024-11-30 15:32:42,793] Trial 48 finished with value: 0.002771738953676752 and parameters: {'hidden_size': 64, 'num_layers': 2, 'learning_rate': 0.00820893497822612, 'batch_size': 32, 'num_epochs': 59}. Best is trial 20 with value: 0.0021563288120722227.\n",
      "[I 2024-11-30 15:33:34,299] Trial 49 finished with value: 0.006171902874484658 and parameters: {'hidden_size': 128, 'num_layers': 1, 'learning_rate': 0.0038803126128692748, 'batch_size': 128, 'num_epochs': 61}. Best is trial 20 with value: 0.0021563288120722227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros: {'hidden_size': 128, 'num_layers': 2, 'learning_rate': 0.005130547232547332, 'batch_size': 32, 'num_epochs': 43}\n",
      "Melhor loss: 0.0021563288120722227\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'output_size'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 25\u001B[0m\n\u001B[0;32m     23\u001B[0m hidden_size \u001B[38;5;241m=\u001B[39m estudo\u001B[38;5;241m.\u001B[39mbest_params[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhidden_size\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m     24\u001B[0m num_layers \u001B[38;5;241m=\u001B[39m estudo\u001B[38;5;241m.\u001B[39mbest_params[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnum_layers\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m---> 25\u001B[0m output_size \u001B[38;5;241m=\u001B[39m \u001B[43mestudo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbest_params\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43moutput_size\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[0;32m     26\u001B[0m num_epochs \u001B[38;5;241m=\u001B[39m estudo\u001B[38;5;241m.\u001B[39mbest_params[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnum_epochs\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m     27\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m estudo\u001B[38;5;241m.\u001B[39mbest_params[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbatch_size\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "\u001B[1;31mKeyError\u001B[0m: 'output_size'"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Treinamento do modelo com os melhores parâmetros",
   "id": "4ce8a4ad090217a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T19:04:06.428435Z",
     "start_time": "2024-11-30T19:02:01.943936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_size = data.shape[1]\n",
    "hidden_size = estudo.best_params['hidden_size']\n",
    "num_layers = estudo.best_params['num_layers']\n",
    "num_epochs = estudo.best_params['num_epochs']\n",
    "batch_size = estudo.best_params['batch_size']\n",
    "learning_rate = estudo.best_params['learning_rate']\n",
    "sequence_length = 20\n",
    "output_size = 1\n",
    "\n",
    "train_dataset = TensorDataset(train_X, train_y)\n",
    "test_dataset = TensorDataset(test_X, test_y)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = train_model()"
   ],
   "id": "b752e17655722dcc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/43], Step [1/44], Loss: 0.3379\n",
      "Epoch [2/43], Step [1/44], Loss: 0.0037\n",
      "Epoch [3/43], Step [1/44], Loss: 0.0016\n",
      "Epoch [4/43], Step [1/44], Loss: 0.0027\n",
      "Epoch [5/43], Step [1/44], Loss: 0.0009\n",
      "Epoch [6/43], Step [1/44], Loss: 0.0018\n",
      "Epoch [7/43], Step [1/44], Loss: 0.0010\n",
      "Epoch [8/43], Step [1/44], Loss: 0.0011\n",
      "Epoch [9/43], Step [1/44], Loss: 0.0010\n",
      "Epoch [10/43], Step [1/44], Loss: 0.0019\n",
      "Epoch [11/43], Step [1/44], Loss: 0.0008\n",
      "Epoch [12/43], Step [1/44], Loss: 0.0009\n",
      "Epoch [13/43], Step [1/44], Loss: 0.0004\n",
      "Epoch [14/43], Step [1/44], Loss: 0.0017\n",
      "Epoch [15/43], Step [1/44], Loss: 0.0008\n",
      "Epoch [16/43], Step [1/44], Loss: 0.0003\n",
      "Epoch [17/43], Step [1/44], Loss: 0.0010\n",
      "Epoch [18/43], Step [1/44], Loss: 0.0006\n",
      "Epoch [19/43], Step [1/44], Loss: 0.0011\n",
      "Epoch [20/43], Step [1/44], Loss: 0.0014\n",
      "Epoch [21/43], Step [1/44], Loss: 0.0005\n",
      "Epoch [22/43], Step [1/44], Loss: 0.0013\n",
      "Epoch [23/43], Step [1/44], Loss: 0.0007\n",
      "Epoch [24/43], Step [1/44], Loss: 0.0008\n",
      "Epoch [25/43], Step [1/44], Loss: 0.0013\n",
      "Epoch [26/43], Step [1/44], Loss: 0.0003\n",
      "Epoch [27/43], Step [1/44], Loss: 0.0003\n",
      "Epoch [28/43], Step [1/44], Loss: 0.0007\n",
      "Epoch [29/43], Step [1/44], Loss: 0.0011\n",
      "Epoch [30/43], Step [1/44], Loss: 0.0015\n",
      "Epoch [31/43], Step [1/44], Loss: 0.0006\n",
      "Epoch [32/43], Step [1/44], Loss: 0.0007\n",
      "Epoch [33/43], Step [1/44], Loss: 0.0005\n",
      "Epoch [34/43], Step [1/44], Loss: 0.0008\n",
      "Epoch [35/43], Step [1/44], Loss: 0.0005\n",
      "Epoch [36/43], Step [1/44], Loss: 0.0007\n",
      "Epoch [37/43], Step [1/44], Loss: 0.0006\n",
      "Epoch [38/43], Step [1/44], Loss: 0.0003\n",
      "Epoch [39/43], Step [1/44], Loss: 0.0005\n",
      "Epoch [40/43], Step [1/44], Loss: 0.0011\n",
      "Epoch [41/43], Step [1/44], Loss: 0.0010\n",
      "Epoch [42/43], Step [1/44], Loss: 0.0004\n",
      "Epoch [43/43], Step [1/44], Loss: 0.0016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/8 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b445dca35f764744a866bd9f7b1943cc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T19:05:06.648410Z",
     "start_time": "2024-11-30T19:05:05.997381Z"
    }
   },
   "cell_type": "code",
   "source": "evaluate_model2(model, nn.MSELoss())",
   "id": "386baceb4e4230e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0036\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T19:20:08.916565Z",
     "start_time": "2024-11-30T19:20:08.889977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mlflow.end_run()\n",
    "torch.save(model.state_dict(), 'modelo_aapl_lstm.pth')\n",
    "torch.save(scaler, 'escala.pkl')"
   ],
   "id": "a1f071428a0849d3",
   "outputs": [],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
